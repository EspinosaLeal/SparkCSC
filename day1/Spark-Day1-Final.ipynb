{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The idea of this exercise to perform simple text analysis, a popular concept used in many cutting-edge applications. Also, known as Text Mining - the idea is to retrieve high-quality information from the text. Some of the text mining tasks are: text categorization, text clustering, concept/entity extraction, sentiment analysis, document summarization etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on a custom query, we will try to find the similar documents from our pool of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the text file in zipped format, yes that's possible!\n",
    "t = sc.textFile('data/test.ft.txt.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__label__2 Great CD: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I\\'m in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life\\'s hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"Who was that singing ?\"',\n",
       " \"__label__2 One of the best game music soundtracks - for a game I didn't really play: Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there's not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren't included I would still consider the collection worth it.\",\n",
       " '__label__1 Batteries died within a year ...: I bought this charger in Jul 2003 and it worked OK for a while. The design is nice and convenient. However, after about a year, the batteries would not hold a charge. Might as well just get alkaline disposables, or look elsewhere for a charger that comes with batteries that have better staying power.',\n",
       " \"__label__2 works fine, but Maha Energy is better: Check out Maha Energy's website. Their Powerex MH-C204F charger works in 100 minutes for rapid charge, with option for slower charge (better for batteries). And they have 2200 mAh batteries.\",\n",
       " \"__label__2 Great for the non-audiophile: Reviewed quite a bit of the combo players and was hesitant due to unfavorable reviews and size of machines. I am weaning off my VHS collection, but don't want to replace them with DVD's. This unit is well built, easy to setup and resolution and special effects (no progressive scan for HDTV owners) suitable for many people looking for a versatile product.Cons- No universal remote.\",\n",
       " \"__label__1 DVD Player crapped out after one year: I also began having the incorrect disc problems that I've read about on here. The VCR still works, but hte DVD side is useless. I understand that DVD players sometimes just quit on you, but after not even one year? To me that's a sign on bad quality. I'm giving up JVC after this as well. I'm sticking to Sony or giving another brand a shot.\",\n",
       " \"__label__1 Incorrect Disc: I love the style of this, but after a couple years, the DVD is giving me problems. It doesn't even work anymore and I use my broken PS2 Now. I wouldn't recommend this, I'm just going to upgrade to a recorder now. I wish it would work but I guess i'm giving up on JVC. I really did like this one... before it stopped working. The dvd player gave me problems probably after a year of having it.\",\n",
       " \"__label__1 DVD menu select problems: I cannot scroll through a DVD menu that is set up vertically. The triangle keys will only select horizontally. So I cannot select anything on most DVD's besides play. No special features, no language select, nothing, just play.\",\n",
       " '__label__2 Unique Weird Orientalia from the 1930\\'s: Exotic tales of the Orient from the 1930\\'s. \"Dr Shen Fu\", a Weird Tales magazine reprint, is about the elixir of life that grants immortality at a price. If you\\'re tired of modern authors who all sound alike, this is the antidote for you. Owen\\'s palette is loaded with splashes of Chinese and Japanese colours. Marvelous.',\n",
       " '__label__1 Not an \"ultimate guide\": Firstly,I enjoyed the format and tone of the book (how the author addressed the reader). However, I did not feel that she imparted any insider secrets that the book promised to reveal. If you are just starting to research law school, and do not know all the requirements of admission, then this book may be a tremendous help. If you have done your homework and are looking for an edge when it comes to admissions, I recommend some more topic-specific books. For example, books on how to write your personal statment, books geared specifically towards LSAT preparation (Powerscore books were the most helpful for me), and there are some websites with great advice geared towards aiding the individuals whom you are asking to write letters of recommendation. Yet, for those new to the entire affair, this book can definitely clarify the requirements for you.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look how the data looks like\n",
    "t.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stopwords: The list of most frequenty used words in a specific language. Stopwords do not offer any useful information about a chunk of text, so we generally remove them from the text before progressing further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('stopwords.txt', <http.client.HTTPMessage at 0x7f20b9d28b38>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute this cell to download the list of English stopwords\n",
    "import urllib.request as urllib\n",
    "urllib.urlretrieve (\"https://raw.githubusercontent.com/stanfordnlp/CoreNLP/master/data/edu/stanford/nlp/patterns/surface/stopwords.txt\", \"stopwords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = sc.textFile(\"stopwords.txt\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the total dataset into two parts, if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train,test = t.randomSplit(weights=[0.9, 0.1], seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of partitions\n",
    "train.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Increase the number of partitions\n",
    "train = train.repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.getNumPartitions() # Check again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[10] at coalesce at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.persist() # Store the RDD in memory for quicker operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the text into 'tokens' (individual words) by whitespace\n",
    "traw = train.map(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discard the first token(word) and take rest\n",
    "tdata = traw.map(lambda x: x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = tdata.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['very', 'disappointing:', 'The', 'movie', 'is', 'vulgar', 'and', 'not', 'meant', 'for', 'children.', 'It', 'is', 'a', 'typical', 'Adam', 'Sandler', 'movie,', 'with', 'foul', 'language', 'and', 'raunchy', 'humor.', 'Not', 'enjoyable', 'at', 'all.']]\n"
     ]
    }
   ],
   "source": [
    "for i in xxx:\n",
    "    print(xxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function which tries to eliminate all the special characters in tokens(words)\n",
    "# Also, only take words which have length more than 2!\n",
    "# Hint: Use regex, the module in python is re\n",
    "# Input: x -> list of words/tokens\n",
    "# Outout: list of words/tokens with length more than 2 and without any special characters\n",
    "import re\n",
    "def replace_special_chars(x):\n",
    "    return [re.sub('[^a-zA-Z0-9]|\\.', '', nelem) for nelem in x if len(nelem)>2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['very',\n",
       "  'disappointing',\n",
       "  'The',\n",
       "  'movie',\n",
       "  'vulgar',\n",
       "  'and',\n",
       "  'not',\n",
       "  'meant',\n",
       "  'for',\n",
       "  'children',\n",
       "  'typical',\n",
       "  'Adam',\n",
       "  'Sandler',\n",
       "  'movie',\n",
       "  'with',\n",
       "  'foul',\n",
       "  'language',\n",
       "  'and',\n",
       "  'raunchy',\n",
       "  'humor',\n",
       "  'Not',\n",
       "  'enjoyable',\n",
       "  'all'],\n",
       " ['Sandler',\n",
       "  'Strikes',\n",
       "  'Out',\n",
       "  'Crazy',\n",
       "  'Nights',\n",
       "  'might',\n",
       "  'have',\n",
       "  'been',\n",
       "  'sweet',\n",
       "  'film',\n",
       "  'with',\n",
       "  'good',\n",
       "  'message',\n",
       "  'for',\n",
       "  'kids',\n",
       "  'but',\n",
       "  'the',\n",
       "  'scatological',\n",
       "  'humor',\n",
       "  'offensive',\n",
       "  'language',\n",
       "  'and',\n",
       "  'explicit',\n",
       "  'sexual',\n",
       "  'references',\n",
       "  'made',\n",
       "  'unsuitable',\n",
       "  'for',\n",
       "  '10year',\n",
       "  'old',\n",
       "  'The',\n",
       "  'plot',\n",
       "  'the',\n",
       "  'other',\n",
       "  'hand',\n",
       "  'while',\n",
       "  'fine',\n",
       "  'for',\n",
       "  '10year',\n",
       "  'olds',\n",
       "  'was',\n",
       "  'too',\n",
       "  'obvious',\n",
       "  'and',\n",
       "  'simplistic',\n",
       "  'for',\n",
       "  'most',\n",
       "  'the',\n",
       "  'adults',\n",
       "  'the',\n",
       "  'audience',\n",
       "  'result',\n",
       "  'while',\n",
       "  'its',\n",
       "  'probably',\n",
       "  'not',\n",
       "  'the',\n",
       "  'worst',\n",
       "  'film',\n",
       "  'the',\n",
       "  'year',\n",
       "  'certainly',\n",
       "  'the',\n",
       "  'running'],\n",
       " ['Not',\n",
       "  'the',\n",
       "  'worst',\n",
       "  'but',\n",
       "  'far',\n",
       "  'from',\n",
       "  'good',\n",
       "  'This',\n",
       "  'film',\n",
       "  'has',\n",
       "  'the',\n",
       "  'dubious',\n",
       "  'honor',\n",
       "  'included',\n",
       "  'the',\n",
       "  'book',\n",
       "  'The',\n",
       "  'worst',\n",
       "  'films',\n",
       "  'all',\n",
       "  'time',\n",
       "  'definently',\n",
       "  'not',\n",
       "  'one',\n",
       "  'those',\n",
       "  'but',\n",
       "  'one',\n",
       "  'can',\n",
       "  'hardly',\n",
       "  'call',\n",
       "  'proper',\n",
       "  'film',\n",
       "  'either',\n",
       "  'rather',\n",
       "  'loose',\n",
       "  'framework',\n",
       "  'which',\n",
       "  'new',\n",
       "  'songs',\n",
       "  'could',\n",
       "  'presented',\n",
       "  'more',\n",
       "  'less',\n",
       "  'natural',\n",
       "  'manner',\n",
       "  'greatgreatgrandfather',\n",
       "  'music',\n",
       "  'videos',\n",
       "  'and',\n",
       "  'better',\n",
       "  'than',\n",
       "  'some',\n",
       "  'those'],\n",
       " ['Been',\n",
       "  'waiting',\n",
       "  'for',\n",
       "  'foreign',\n",
       "  'lauguage',\n",
       "  'AOL',\n",
       "  'CD',\n",
       "  'have',\n",
       "  'too',\n",
       "  'but',\n",
       "  'this',\n",
       "  'isnt',\n",
       "  'it',\n",
       "  'The',\n",
       "  'translation',\n",
       "  'very',\n",
       "  'choppy',\n",
       "  'the',\n",
       "  'singers',\n",
       "  'are',\n",
       "  'medicore',\n",
       "  'best',\n",
       "  'and',\n",
       "  'the',\n",
       "  'orchestrations',\n",
       "  'are',\n",
       "  'too',\n",
       "  'overwhelming',\n",
       "  'Love',\n",
       "  'Changes',\n",
       "  'Everything',\n",
       "  'shredded',\n",
       "  'the',\n",
       "  'point',\n",
       "  'where',\n",
       "  'hurts',\n",
       "  'listen',\n",
       "  'itOddly',\n",
       "  'the',\n",
       "  'best',\n",
       "  'song',\n",
       "  'the',\n",
       "  'French',\n",
       "  'Chanson',\n",
       "  'dEnfanceI',\n",
       "  'was',\n",
       "  'very',\n",
       "  'surprised',\n",
       "  'the',\n",
       "  'Japanese',\n",
       "  'usually',\n",
       "  'put',\n",
       "  'out',\n",
       "  'extramely',\n",
       "  'good',\n",
       "  'cast',\n",
       "  'CDS',\n",
       "  'Their',\n",
       "  'CATS',\n",
       "  'and',\n",
       "  'Phantom',\n",
       "  'and',\n",
       "  'the',\n",
       "  'Tokoyo',\n",
       "  'Evita',\n",
       "  'are',\n",
       "  'all',\n",
       "  'great',\n",
       "  'But',\n",
       "  'unless',\n",
       "  'you',\n",
       "  'are',\n",
       "  'total',\n",
       "  'ALW',\n",
       "  'AOL',\n",
       "  'fanatic',\n",
       "  'save',\n",
       "  'your',\n",
       "  'money'],\n",
       " ['Itten',\n",
       "  'The',\n",
       "  'Elements',\n",
       "  'Color',\n",
       "  'was',\n",
       "  'very',\n",
       "  'pleased',\n",
       "  'review',\n",
       "  'the',\n",
       "  'art',\n",
       "  'book',\n",
       "  'which',\n",
       "  'arrived',\n",
       "  'pristine',\n",
       "  'condition',\n",
       "  'would',\n",
       "  'have',\n",
       "  'rated',\n",
       "  'Excellent',\n",
       "  'condition',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'very',\n",
       "  'good',\n",
       "  'would',\n",
       "  'like',\n",
       "  'thank',\n",
       "  'the',\n",
       "  'person',\n",
       "  'who',\n",
       "  'made',\n",
       "  'possible',\n",
       "  'but',\n",
       "  'have',\n",
       "  'misplaced',\n",
       "  'her',\n",
       "  'name',\n",
       "  'and',\n",
       "  'address'],\n",
       " ['wish',\n",
       "  'i',\n",
       "  'had',\n",
       "  'never',\n",
       "  'heard',\n",
       "  'Fair',\n",
       "  'Midland',\n",
       "  'before',\n",
       "  'hearing',\n",
       "  'this',\n",
       "  'music',\n",
       "  'but',\n",
       "  'cant',\n",
       "  'help',\n",
       "  'making',\n",
       "  'comparisons',\n",
       "  'still',\n",
       "  'wonderful',\n",
       "  'music',\n",
       "  'and',\n",
       "  'Ill',\n",
       "  'explore',\n",
       "  'further'],\n",
       " ['Good',\n",
       "  'followup',\n",
       "  'Cielo',\n",
       "  'bit',\n",
       "  'change',\n",
       "  'this',\n",
       "  'time',\n",
       "  'for',\n",
       "  'Dredg',\n",
       "  'less',\n",
       "  'progressive',\n",
       "  'material',\n",
       "  'more',\n",
       "  'straight',\n",
       "  'ahead',\n",
       "  'rock',\n",
       "  'tunes',\n",
       "  'was',\n",
       "  'little',\n",
       "  'disappointed',\n",
       "  'it',\n",
       "  'doesnt',\n",
       "  'have',\n",
       "  'alot',\n",
       "  'stuff',\n",
       "  'going',\n",
       "  'like',\n",
       "  'with',\n",
       "  'Cielo',\n",
       "  'which',\n",
       "  'pretty',\n",
       "  'big',\n",
       "  'compared',\n",
       "  'Catch',\n",
       "  'Without',\n",
       "  'Arms',\n",
       "  'But',\n",
       "  'still',\n",
       "  'this',\n",
       "  'the',\n",
       "  'direction',\n",
       "  'they',\n",
       "  'chose',\n",
       "  'and',\n",
       "  'its',\n",
       "  'definitely',\n",
       "  'very',\n",
       "  'good',\n",
       "  'one'],\n",
       " ['WOW',\n",
       "  'This',\n",
       "  'book',\n",
       "  'really',\n",
       "  'bothers',\n",
       "  'me',\n",
       "  'you',\n",
       "  'are',\n",
       "  'parent',\n",
       "  'trying',\n",
       "  'deal',\n",
       "  'with',\n",
       "  'the',\n",
       "  'daily',\n",
       "  'struggles',\n",
       "  'having',\n",
       "  'child',\n",
       "  'with',\n",
       "  'disability',\n",
       "  'not',\n",
       "  'read',\n",
       "  'this',\n",
       "  'book',\n",
       "  'does',\n",
       "  'not',\n",
       "  'offer',\n",
       "  'any',\n",
       "  'advice',\n",
       "  'for',\n",
       "  'parents',\n",
       "  'just',\n",
       "  'helps',\n",
       "  'fuel',\n",
       "  'negativitiy',\n",
       "  'Please',\n",
       "  'not',\n",
       "  'put',\n",
       "  'yourself',\n",
       "  'through',\n",
       "  'reading',\n",
       "  'this',\n",
       "  'book',\n",
       "  'you',\n",
       "  'are',\n",
       "  'still',\n",
       "  'the',\n",
       "  'grieving',\n",
       "  'stage',\n",
       "  'this',\n",
       "  'book',\n",
       "  'will',\n",
       "  'not',\n",
       "  'help',\n",
       "  'you',\n",
       "  'parents',\n",
       "  'please',\n",
       "  'try',\n",
       "  'surrounding',\n",
       "  'yourself',\n",
       "  'with',\n",
       "  'positives',\n",
       "  'Children',\n",
       "  'with',\n",
       "  'disabilities',\n",
       "  'can',\n",
       "  'bring',\n",
       "  'such',\n",
       "  'joy',\n",
       "  'your',\n",
       "  'life',\n",
       "  'They',\n",
       "  'can',\n",
       "  'help',\n",
       "  'you',\n",
       "  'learn',\n",
       "  'help',\n",
       "  'you',\n",
       "  'become',\n",
       "  'more',\n",
       "  'empathetic',\n",
       "  'help',\n",
       "  'you',\n",
       "  'become',\n",
       "  'stronger',\n",
       "  'and',\n",
       "  'bring',\n",
       "  'wonderful',\n",
       "  'caring',\n",
       "  'people',\n",
       "  'into',\n",
       "  'your',\n",
       "  'life',\n",
       "  'Please',\n",
       "  'remember',\n",
       "  'those',\n",
       "  'things',\n",
       "  'when',\n",
       "  'trying',\n",
       "  'get',\n",
       "  'through',\n",
       "  'this',\n",
       "  'time',\n",
       "  'your',\n",
       "  'life',\n",
       "  'not',\n",
       "  'waste',\n",
       "  'your',\n",
       "  'time',\n",
       "  'listening',\n",
       "  'families',\n",
       "  'stories',\n",
       "  'frustration',\n",
       "  'anger',\n",
       "  'sadness',\n",
       "  'and',\n",
       "  'embarrassment',\n",
       "  'instead',\n",
       "  'surround',\n",
       "  'yourself',\n",
       "  'with',\n",
       "  'positives'],\n",
       " ['80s',\n",
       "  'Hard',\n",
       "  'Rock',\n",
       "  'One',\n",
       "  'the',\n",
       "  '80s',\n",
       "  'rock',\n",
       "  'bands',\n",
       "  'that',\n",
       "  'capture',\n",
       "  'ears',\n",
       "  'Its',\n",
       "  'pity',\n",
       "  'that',\n",
       "  'they',\n",
       "  'are',\n",
       "  'almost',\n",
       "  'retiring',\n",
       "  'soon'],\n",
       " ['Low',\n",
       "  'class',\n",
       "  'effort',\n",
       "  'High',\n",
       "  'Class',\n",
       "  'Band',\n",
       "  'This',\n",
       "  'material',\n",
       "  'represents',\n",
       "  'why',\n",
       "  'the',\n",
       "  '80s',\n",
       "  'died',\n",
       "  'the',\n",
       "  'music',\n",
       "  'bland',\n",
       "  'and',\n",
       "  'poppy',\n",
       "  'the',\n",
       "  'Wilson',\n",
       "  'sisters',\n",
       "  'garnered',\n",
       "  'their',\n",
       "  'wigs',\n",
       "  'and',\n",
       "  'corsets',\n",
       "  'and',\n",
       "  'the',\n",
       "  'the',\n",
       "  'music',\n",
       "  'became',\n",
       "  'something',\n",
       "  'inside',\n",
       "  'joke',\n",
       "  'those',\n",
       "  'mentioning',\n",
       "  'real',\n",
       "  'bands',\n",
       "  'Looking',\n",
       "  'back',\n",
       "  'the',\n",
       "  'the',\n",
       "  'music',\n",
       "  'very',\n",
       "  'dated',\n",
       "  'and',\n",
       "  'caught',\n",
       "  'era',\n",
       "  'best',\n",
       "  'left',\n",
       "  'forgotten']]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_semi_clean = tdata.map(replace_special_chars)\n",
    "t_semi_clean.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that would make the tokens(words) lowercase and then check if it's a stopword or not.\n",
    "# If stopword, then discard it\n",
    "# Input: x -> list of words/tokens\n",
    "# Outout: list of words/tokens without stopwords\n",
    "def remove_sw(x):\n",
    "    # Write your code here\n",
    "    return [elm.lower() for elm in x if elm.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['disappointing',\n",
       "  'movie',\n",
       "  'vulgar',\n",
       "  'meant',\n",
       "  'children',\n",
       "  'typical',\n",
       "  'adam',\n",
       "  'sandler',\n",
       "  'movie',\n",
       "  'foul',\n",
       "  'language',\n",
       "  'raunchy',\n",
       "  'humor',\n",
       "  'enjoyable']]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_clean = t_semi_clean.map(remove_sw)\n",
    "t_clean.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency (TF): The number of times a specific word occurs in a record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF of term 't' in a document 'd' = Number of times term 't' occurs in a document or record 'd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a function which takes the rdd item (record) and \n",
    "# then tries to count the occurances of a specific word in the whole record\n",
    "# Input: record -> list of words/tokens\n",
    "# Output: list of (word, frequency of occurance)\n",
    "def tf(record):\n",
    "    counts = {}\n",
    "    # Write your code here\n",
    "    for word in record:  # Looping, Why?\n",
    "        if word not in counts:\n",
    "            counts[word] = 1\n",
    "        else:\n",
    "            counts[word] += 1\n",
    "    return list(counts.items()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('disappointing', 1),\n",
       "  ('movie', 2),\n",
       "  ('vulgar', 1),\n",
       "  ('meant', 1),\n",
       "  ('children', 1),\n",
       "  ('typical', 1),\n",
       "  ('adam', 1),\n",
       "  ('sandler', 1),\n",
       "  ('foul', 1),\n",
       "  ('language', 1),\n",
       "  ('raunchy', 1),\n",
       "  ('humor', 1),\n",
       "  ('enjoyable', 1)],\n",
       " [('sandler', 1),\n",
       "  ('strikes', 1),\n",
       "  ('crazy', 1),\n",
       "  ('nights', 1),\n",
       "  ('might', 1),\n",
       "  ('sweet', 1),\n",
       "  ('film', 2),\n",
       "  ('good', 1),\n",
       "  ('message', 1),\n",
       "  ('kids', 1),\n",
       "  ('scatological', 1),\n",
       "  ('humor', 1),\n",
       "  ('offensive', 1),\n",
       "  ('language', 1),\n",
       "  ('explicit', 1),\n",
       "  ('sexual', 1),\n",
       "  ('references', 1),\n",
       "  ('made', 1),\n",
       "  ('unsuitable', 1),\n",
       "  ('10year', 2),\n",
       "  ('old', 1),\n",
       "  ('plot', 1),\n",
       "  ('hand', 1),\n",
       "  ('fine', 1),\n",
       "  ('olds', 1),\n",
       "  ('obvious', 1),\n",
       "  ('simplistic', 1),\n",
       "  ('adults', 1),\n",
       "  ('audience', 1),\n",
       "  ('result', 1),\n",
       "  ('probably', 1),\n",
       "  ('worst', 1),\n",
       "  ('year', 1),\n",
       "  ('certainly', 1),\n",
       "  ('running', 1)],\n",
       " [('worst', 2),\n",
       "  ('far', 1),\n",
       "  ('good', 1),\n",
       "  ('film', 2),\n",
       "  ('dubious', 1),\n",
       "  ('honor', 1),\n",
       "  ('included', 1),\n",
       "  ('book', 1),\n",
       "  ('films', 1),\n",
       "  ('time', 1),\n",
       "  ('definently', 1),\n",
       "  ('one', 2),\n",
       "  ('hardly', 1),\n",
       "  ('call', 1),\n",
       "  ('proper', 1),\n",
       "  ('either', 1),\n",
       "  ('rather', 1),\n",
       "  ('loose', 1),\n",
       "  ('framework', 1),\n",
       "  ('new', 1),\n",
       "  ('songs', 1),\n",
       "  ('presented', 1),\n",
       "  ('less', 1),\n",
       "  ('natural', 1),\n",
       "  ('manner', 1),\n",
       "  ('greatgreatgrandfather', 1),\n",
       "  ('music', 1),\n",
       "  ('videos', 1),\n",
       "  ('better', 1)],\n",
       " [('waiting', 1),\n",
       "  ('foreign', 1),\n",
       "  ('lauguage', 1),\n",
       "  ('aol', 2),\n",
       "  ('cd', 1),\n",
       "  ('translation', 1),\n",
       "  ('choppy', 1),\n",
       "  ('singers', 1),\n",
       "  ('medicore', 1),\n",
       "  ('best', 2),\n",
       "  ('orchestrations', 1),\n",
       "  ('overwhelming', 1),\n",
       "  ('love', 1),\n",
       "  ('changes', 1),\n",
       "  ('everything', 1),\n",
       "  ('shredded', 1),\n",
       "  ('point', 1),\n",
       "  ('hurts', 1),\n",
       "  ('listen', 1),\n",
       "  ('itoddly', 1),\n",
       "  ('song', 1),\n",
       "  ('french', 1),\n",
       "  ('chanson', 1),\n",
       "  ('denfancei', 1),\n",
       "  ('surprised', 1),\n",
       "  ('japanese', 1),\n",
       "  ('usually', 1),\n",
       "  ('put', 1),\n",
       "  ('extramely', 1),\n",
       "  ('good', 1),\n",
       "  ('cast', 1),\n",
       "  ('cds', 1),\n",
       "  ('cats', 1),\n",
       "  ('phantom', 1),\n",
       "  ('tokoyo', 1),\n",
       "  ('evita', 1),\n",
       "  ('great', 1),\n",
       "  ('unless', 1),\n",
       "  ('total', 1),\n",
       "  ('alw', 1),\n",
       "  ('fanatic', 1),\n",
       "  ('save', 1),\n",
       "  ('money', 1)],\n",
       " [('itten', 1),\n",
       "  ('elements', 1),\n",
       "  ('color', 1),\n",
       "  ('pleased', 1),\n",
       "  ('review', 1),\n",
       "  ('art', 1),\n",
       "  ('book', 1),\n",
       "  ('arrived', 1),\n",
       "  ('pristine', 1),\n",
       "  ('condition', 2),\n",
       "  ('rated', 1),\n",
       "  ('excellent', 1),\n",
       "  ('rather', 1),\n",
       "  ('good', 1),\n",
       "  ('like', 1),\n",
       "  ('thank', 1),\n",
       "  ('person', 1),\n",
       "  ('made', 1),\n",
       "  ('possible', 1),\n",
       "  ('misplaced', 1),\n",
       "  ('name', 1),\n",
       "  ('address', 1)],\n",
       " [('wish', 1),\n",
       "  ('never', 1),\n",
       "  ('heard', 1),\n",
       "  ('fair', 1),\n",
       "  ('midland', 1),\n",
       "  ('hearing', 1),\n",
       "  ('music', 2),\n",
       "  ('help', 1),\n",
       "  ('making', 1),\n",
       "  ('comparisons', 1),\n",
       "  ('still', 1),\n",
       "  ('wonderful', 1),\n",
       "  ('ill', 1),\n",
       "  ('explore', 1)],\n",
       " [('good', 2),\n",
       "  ('followup', 1),\n",
       "  ('cielo', 2),\n",
       "  ('bit', 1),\n",
       "  ('change', 1),\n",
       "  ('time', 1),\n",
       "  ('dredg', 1),\n",
       "  ('less', 1),\n",
       "  ('progressive', 1),\n",
       "  ('material', 1),\n",
       "  ('straight', 1),\n",
       "  ('ahead', 1),\n",
       "  ('rock', 1),\n",
       "  ('tunes', 1),\n",
       "  ('little', 1),\n",
       "  ('disappointed', 1),\n",
       "  ('alot', 1),\n",
       "  ('stuff', 1),\n",
       "  ('going', 1),\n",
       "  ('like', 1),\n",
       "  ('pretty', 1),\n",
       "  ('big', 1),\n",
       "  ('compared', 1),\n",
       "  ('catch', 1),\n",
       "  ('without', 1),\n",
       "  ('arms', 1),\n",
       "  ('still', 1),\n",
       "  ('direction', 1),\n",
       "  ('chose', 1),\n",
       "  ('definitely', 1),\n",
       "  ('one', 1)],\n",
       " [('wow', 1),\n",
       "  ('book', 4),\n",
       "  ('really', 1),\n",
       "  ('bothers', 1),\n",
       "  ('parent', 1),\n",
       "  ('trying', 2),\n",
       "  ('deal', 1),\n",
       "  ('daily', 1),\n",
       "  ('struggles', 1),\n",
       "  ('child', 1),\n",
       "  ('disability', 1),\n",
       "  ('read', 1),\n",
       "  ('offer', 1),\n",
       "  ('advice', 1),\n",
       "  ('parents', 2),\n",
       "  ('just', 1),\n",
       "  ('helps', 1),\n",
       "  ('fuel', 1),\n",
       "  ('negativitiy', 1),\n",
       "  ('please', 3),\n",
       "  ('put', 1),\n",
       "  ('reading', 1),\n",
       "  ('still', 1),\n",
       "  ('grieving', 1),\n",
       "  ('stage', 1),\n",
       "  ('will', 1),\n",
       "  ('help', 4),\n",
       "  ('try', 1),\n",
       "  ('surrounding', 1),\n",
       "  ('positives', 2),\n",
       "  ('children', 1),\n",
       "  ('disabilities', 1),\n",
       "  ('bring', 2),\n",
       "  ('joy', 1),\n",
       "  ('life', 3),\n",
       "  ('learn', 1),\n",
       "  ('become', 2),\n",
       "  ('empathetic', 1),\n",
       "  ('stronger', 1),\n",
       "  ('wonderful', 1),\n",
       "  ('caring', 1),\n",
       "  ('people', 1),\n",
       "  ('remember', 1),\n",
       "  ('things', 1),\n",
       "  ('get', 1),\n",
       "  ('time', 2),\n",
       "  ('waste', 1),\n",
       "  ('listening', 1),\n",
       "  ('families', 1),\n",
       "  ('stories', 1),\n",
       "  ('frustration', 1),\n",
       "  ('anger', 1),\n",
       "  ('sadness', 1),\n",
       "  ('embarrassment', 1),\n",
       "  ('instead', 1),\n",
       "  ('surround', 1)],\n",
       " [('80s', 2),\n",
       "  ('hard', 1),\n",
       "  ('rock', 2),\n",
       "  ('one', 1),\n",
       "  ('bands', 1),\n",
       "  ('capture', 1),\n",
       "  ('ears', 1),\n",
       "  ('pity', 1),\n",
       "  ('almost', 1),\n",
       "  ('retiring', 1),\n",
       "  ('soon', 1)],\n",
       " [('low', 1),\n",
       "  ('class', 2),\n",
       "  ('effort', 1),\n",
       "  ('high', 1),\n",
       "  ('band', 1),\n",
       "  ('material', 1),\n",
       "  ('represents', 1),\n",
       "  ('80s', 1),\n",
       "  ('died', 1),\n",
       "  ('music', 3),\n",
       "  ('bland', 1),\n",
       "  ('poppy', 1),\n",
       "  ('wilson', 1),\n",
       "  ('sisters', 1),\n",
       "  ('garnered', 1),\n",
       "  ('wigs', 1),\n",
       "  ('corsets', 1),\n",
       "  ('became', 1),\n",
       "  ('something', 1),\n",
       "  ('inside', 1),\n",
       "  ('joke', 1),\n",
       "  ('mentioning', 1),\n",
       "  ('real', 1),\n",
       "  ('bands', 1),\n",
       "  ('looking', 1),\n",
       "  ('back', 1),\n",
       "  ('dated', 1),\n",
       "  ('caught', 1),\n",
       "  ('era', 1),\n",
       "  ('best', 1),\n",
       "  ('left', 1),\n",
       "  ('forgotten', 1)]]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_with_tfs = t_clean.map(tf)\n",
    "tokens_with_tfs.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Document Frequency (IDF): How important is a specific word in the whole corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculation of IDF is not as straightforward as TF. \n",
    "#### IDF score of term 't' = log(total number of documents / number of documents containing 't')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Take out the unique words per record from 't_clean' \n",
    "# Hint: Use python 'set' function\n",
    "\n",
    "unique_words_per_record = t_clean.map(lambda x: list(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a helper function to attach '1' to every word\n",
    "# Input: record -> list of words\n",
    "# Output: list of tuples where each tuple is (word, 1)\n",
    "def attach_1_to_words(record):\n",
    "    # Your code here\n",
    "    return [(elm,1) for elm in record]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to attach '1' to each and every word across all records of RDD 'unique_words_per_record'\n",
    "# And Return as a single list. \n",
    "# Which transformation should we use?\n",
    "unique_words_per_record_with_1 = t_clean.flatMap(attach_1_to_words)# unique_words_per_record. YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('disappointing', 1),\n",
       " ('movie', 1),\n",
       " ('vulgar', 1),\n",
       " ('meant', 1),\n",
       " ('children', 1)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words_per_record_with_1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('language', 3853),\n",
       " ('strikes', 319),\n",
       " ('crazy', 2225),\n",
       " ('sexual', 1091),\n",
       " ('references', 1198)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to add up the '1's together for same words \n",
    "# which is basically counting the number of documents where a specific word occurs!\n",
    "# Which transformation?\n",
    "tokens_with_docs_count = unique_words_per_record_with_1.reduceByKey(lambda a,b:a+b)\n",
    "tokens_with_docs_count.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, count the total number of documents\n",
    "docs = t_clean.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359963"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You have the counts for the words in the whole document set, now try to calculate IDF\n",
    "# Hint: use python module \"math\" and then math.log for logarithm\n",
    "# Return: RDD of (token, idf_score)\n",
    "import math\n",
    "tokens_with_idfs = tokens_with_docs_count.map(lambda x: (x[0], math.log(docs/x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('book', 0.6277301356605689),\n",
       " ('one', 1.0030553967683506),\n",
       " ('great', 1.2283240049232733),\n",
       " ('like', 1.2675693884191037),\n",
       " ('good', 1.2718713210308168),\n",
       " ('just', 1.3527353106939637),\n",
       " ('will', 1.6148503100624352),\n",
       " ('get', 1.6623843504641405),\n",
       " ('read', 1.6656115793176205),\n",
       " ('time', 1.7240915000058556)]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the result on the basis of idf scores and take just 10. Which 'action' do we use?\n",
    "tokens_with_idfs.takeOrdered(10, lambda s: s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the idfs for each of the tokens (words) as a python dict (because we need to use it over and over again)\n",
    "tokens_with_idfs_dict = tokens_with_idfs.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456313"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_with_idfs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('disappointing', 1),\n",
       "  ('movie', 2),\n",
       "  ('vulgar', 1),\n",
       "  ('meant', 1),\n",
       "  ('children', 1),\n",
       "  ('typical', 1),\n",
       "  ('adam', 1),\n",
       "  ('sandler', 1),\n",
       "  ('foul', 1),\n",
       "  ('language', 1),\n",
       "  ('raunchy', 1),\n",
       "  ('humor', 1),\n",
       "  ('enjoyable', 1)]]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_with_tfs.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.017898212574991"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_with_idfs_dict['disappointing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF score of a term in a specific document = TF of the term in a specific doc x IDF of the term "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the function tfidf which would take the rdd which has the token counts per document\n",
    "# and then muliply with the IDF score of that term\n",
    "# Input: record -> list of (word, term frequency)\n",
    "# Output: list of (word, tfidf score)\n",
    "def tfidf(record):\n",
    "    return [(elm[0],tokens_with_idfs_dict[elm[0]]*elm[1]) for elm in record if elm[0] in tokens_with_idfs_dict]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('disappointing', 4.017898212574991),\n",
       "  ('movie', 3.622732635577382),\n",
       "  ('vulgar', 7.505489496677982),\n",
       "  ('meant', 5.358318507557967),\n",
       "  ('children', 3.87136493007666),\n",
       "  ('typical', 5.138839479524196),\n",
       "  ('adam', 6.858862331752929),\n",
       "  ('sandler', 7.97347496176748),\n",
       "  ('foul', 7.244680442477297),\n",
       "  ('language', 4.53714918274636),\n",
       "  ('raunchy', 8.13031743326045),\n",
       "  ('humor', 4.67108850402611),\n",
       "  ('enjoyable', 4.621309709029738)],\n",
       " [('sandler', 7.97347496176748),\n",
       "  ('strikes', 7.028565424587673),\n",
       "  ('crazy', 5.086244332772177),\n",
       "  ('nights', 6.228491557337156),\n",
       "  ('might', 3.510444542940512),\n",
       "  ('sweet', 4.885737082740047),\n",
       "  ('film', 5.8561493791445765),\n",
       "  ('good', 1.2718713210308168),\n",
       "  ('message', 4.803857152429578),\n",
       "  ('kids', 3.6310320093379977),\n",
       "  ('scatological', 11.001997058144463),\n",
       "  ('humor', 4.67108850402611),\n",
       "  ('offensive', 6.476591840625233),\n",
       "  ('language', 4.53714918274636),\n",
       "  ('explicit', 7.1661354136818805),\n",
       "  ('sexual', 5.798906541539447),\n",
       "  ('references', 5.705347748697123),\n",
       "  ('made', 2.540739499058528),\n",
       "  ('unsuitable', 8.666622142327425),\n",
       "  ('10year', 18.594497931812075),\n",
       "  ('old', 2.6210436857351747),\n",
       "  ('plot', 3.4986155537038695),\n",
       "  ('hand', 4.187454160884504),\n",
       "  ('fine', 3.5071961294849254),\n",
       "  ('olds', 6.517113038030873),\n",
       "  ('obvious', 5.089395359462205),\n",
       "  ('simplistic', 6.359210008585064),\n",
       "  ('adults', 5.3864388169031),\n",
       "  ('audience', 5.387045797194877),\n",
       "  ('result', 5.1536333546771536),\n",
       "  ('probably', 3.53901656809965),\n",
       "  ('worst', 3.501467572749167),\n",
       "  ('year', 3.033504442923142),\n",
       "  ('certainly', 4.406899837684283),\n",
       "  ('running', 4.6827286891788376)],\n",
       " [('worst', 7.002935145498334),\n",
       "  ('far', 3.1529983059325937),\n",
       "  ('good', 1.2718713210308168),\n",
       "  ('film', 5.8561493791445765),\n",
       "  ('dubious', 7.981572172000099),\n",
       "  ('honor', 6.335418244027728),\n",
       "  ('included', 4.537408754454501),\n",
       "  ('book', 0.6277301356605689),\n",
       "  ('films', 4.552316837542787),\n",
       "  ('time', 1.7240915000058556),\n",
       "  ('definently', 9.535659989351036),\n",
       "  ('one', 2.0061107935367013),\n",
       "  ('hardly', 5.216122694769789),\n",
       "  ('call', 4.327435666330037),\n",
       "  ('proper', 5.80166009995663),\n",
       "  ('either', 3.839470370167804),\n",
       "  ('rather', 3.7766368930592895),\n",
       "  ('loose', 5.158452641113103),\n",
       "  ('framework', 7.7311614943455504),\n",
       "  ('new', 2.3150892219319874),\n",
       "  ('songs', 2.801708797856909),\n",
       "  ('presented', 5.298214583488261),\n",
       "  ('less', 3.4708020110272),\n",
       "  ('natural', 5.262740195294602),\n",
       "  ('manner', 5.563193373963225),\n",
       "  ('greatgreatgrandfather', 12.100609346812572),\n",
       "  ('music', 2.472249668156873),\n",
       "  ('videos', 5.175505429495822),\n",
       "  ('better', 2.1856132720935753)],\n",
       " [('waiting', 4.5768579464589045),\n",
       "  ('foreign', 6.524660243666256),\n",
       "  ('lauguage', 11.184318614938418),\n",
       "  ('aol', 17.466627033652195),\n",
       "  ('cd', 3.4381044242362804),\n",
       "  ('translation', 5.879025634653955),\n",
       "  ('choppy', 7.047553336832364),\n",
       "  ('singers', 5.8267893887585345),\n",
       "  ('medicore', 9.849317548206077),\n",
       "  ('best', 4.317629920243714),\n",
       "  ('orchestrations', 8.90193622926189),\n",
       "  ('overwhelming', 6.792341649411367),\n",
       "  ('love', 2.058164523388654),\n",
       "  ('changes', 5.379786237182072),\n",
       "  ('everything', 3.513330547829647),\n",
       "  ('shredded', 8.327848408717934),\n",
       "  ('point', 3.6841208595179666),\n",
       "  ('hurts', 6.787403367770785),\n",
       "  ('listen', 3.6468885783519083),\n",
       "  ('itoddly', 12.793756527372517),\n",
       "  ('song', 3.197881682777049),\n",
       "  ('french', 5.272980112309719),\n",
       "  ('chanson', 10.714314985692681),\n",
       "  ('denfancei', 12.793756527372517),\n",
       "  ('surprised', 4.6651713269980215),\n",
       "  ('japanese', 5.54099410931933),\n",
       "  ('usually', 4.45808521257967),\n",
       "  ('put', 2.767476286249523),\n",
       "  ('extramely', 12.793756527372517),\n",
       "  ('good', 1.2718713210308168),\n",
       "  ('cast', 4.743691104456551),\n",
       "  ('cds', 4.32072423174205),\n",
       "  ('cats', 5.376776905991363),\n",
       "  ('phantom', 7.134274311612896),\n",
       "  ('tokoyo', 12.793756527372517),\n",
       "  ('evita', 9.749234089649095),\n",
       "  ('great', 1.2283240049232733),\n",
       "  ('unless', 4.24972668200272),\n",
       "  ('total', 4.569593014734656),\n",
       "  ('alw', 10.596531950036297),\n",
       "  ('fanatic', 7.27229560951027),\n",
       "  ('save', 3.844521212997663),\n",
       "  ('money', 2.4061775462730353)],\n",
       " [('itten', 12.793756527372517),\n",
       "  ('elements', 5.613686653069721),\n",
       "  ('color', 4.190752679543169),\n",
       "  ('pleased', 4.563445728237497),\n",
       "  ('review', 3.372345185316394),\n",
       "  ('art', 4.5340395663509945),\n",
       "  ('book', 0.6277301356605689),\n",
       "  ('arrived', 4.239460248004778),\n",
       "  ('pristine', 8.261157034219261),\n",
       "  ('condition', 9.45008066931547),\n",
       "  ('rated', 5.449683676799451),\n",
       "  ('excellent', 2.9850742821103013),\n",
       "  ('rather', 3.7766368930592895),\n",
       "  ('good', 1.2718713210308168),\n",
       "  ('like', 1.2675693884191037),\n",
       "  ('thank', 4.503965944190873),\n",
       "  ('person', 3.926470003383102),\n",
       "  ('made', 2.540739499058528),\n",
       "  ('possible', 4.7649753648853705),\n",
       "  ('misplaced', 7.881101641636465),\n",
       "  ('name', 4.111896714401046),\n",
       "  ('address', 5.912345223729982)]]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_docs = tokens_with_tfs.map(tfidf)\n",
    "tfidf_docs.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate cosine similarity :  measure of similarity of two documents i.e. the document vectors and the query vector. The document vectors are the vector representation of our documents which we have already calculated and the query vector will be calcultated based on a custom query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://en.wikipedia.org/wiki/Cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The cosine similarity function\n",
    "# Input: doc_record: data rdd record, query: query rdd record\n",
    "# Output: tuple of (doc_record, cosine similarity score)\n",
    "def cosine_similarity(doc_record, query):\n",
    "    dot_prod = 0.0\n",
    "    norm_record = []\n",
    "    norm_query = []\n",
    "    for query_term in query:\n",
    "        norm_query.append(query[query_term])\n",
    "    for word_tfidf in doc_record:\n",
    "        word = word_tfidf[0]\n",
    "        tfidf = word_tfidf[1]\n",
    "        norm_record.append(tfidf**2)\n",
    "        \n",
    "        if word in query:\n",
    "            dot_prod += query[word] * tfidf\n",
    "        res = dot_prod / math.sqrt(sum(norm_record)) / math.sqrt(sum(norm_query))\n",
    "        return (doc_record, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tuples_to_dict(record):\n",
    "    output = {}\n",
    "    for word_tfidf in record:\n",
    "        word = word_tfidf[0]\n",
    "        tfidf = word_tfidf[1]\n",
    "        output[word] = tfidf\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# condense all previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def querybuilder(querystr=\"\"):\n",
    "    query_rdd_raw = sc.parallelize([tuple(querystr.split(' '))])\n",
    "    query_rs = query_rdd_raw.map(replace_special_chars)\n",
    "    query_sw = query_rs.map(remove_sw)\n",
    "    query_rdd_tf = query_sw.map(tf)\n",
    "    query_rdd_tfidf = query_rdd_tf.map(tfidf)\n",
    "    query_dict = query_rdd_tfidf.map(tuples_to_dict).collect()[0]\n",
    "    return query_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"__label__2 Simple, Durable, Fun game for all ages: This is an AWESOME game! Almost everyone know tic-tac-toe so it is EASY to learn and quick to play. You can't play just once! The twist is that your pieces are slightly different sizes - just big enough to gobble up your opponent. The first person to make tic-tac-toe wins, but it's not as easy as it looks when you're stuck in the mindset of just making three in a row and forget about the gobbling possibilities! My 4 and 5 year olds will beat me even when I'm trying to win! Excellent beginning critical thinking game. Grandparents loved playing it with the kids too.\"]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we will build the 'query' which would be used to find similar documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ages': 5.357728711020669,\n",
       " 'almost': 3.351431799416643,\n",
       " 'awesome': 3.819518307874936,\n",
       " 'beat': 4.77414373297225,\n",
       " 'beginning': 4.355823016941912,\n",
       " 'big': 3.1509197082371396,\n",
       " 'critical': 6.025263315723888,\n",
       " 'different': 3.090428689760224,\n",
       " 'durable': 5.121929729493736,\n",
       " 'easy': 5.728033207384647,\n",
       " 'enough': 3.01651270141064,\n",
       " 'even': 1.9861925346418126,\n",
       " 'everyone': 3.834830588677574,\n",
       " 'excellent': 2.9850742821103013,\n",
       " 'first': 1.9780866710067773,\n",
       " 'forget': 4.850683810094584,\n",
       " 'fun': 3.102039939855632,\n",
       " 'game': 8.119220815571568,\n",
       " 'gobble': 9.960543183316302,\n",
       " 'gobbling': 11.407462166252627,\n",
       " 'grandparents': 7.573400702294192,\n",
       " 'just': 4.058205932081891,\n",
       " 'kids': 3.6310320093379977,\n",
       " 'know': 2.475546845465548,\n",
       " 'learn': 3.967462296131199,\n",
       " 'looks': 3.638400463729094,\n",
       " 'loved': 3.3540519922690684,\n",
       " 'make': 2.4545980246711587,\n",
       " 'making': 3.774455602810012,\n",
       " 'mindset': 7.796544253608403,\n",
       " 'olds': 6.517113038030873,\n",
       " 'opponent': 8.387037280108265,\n",
       " 'person': 3.926470003383102,\n",
       " 'pieces': 4.443326553834382,\n",
       " 'play': 6.483912754528165,\n",
       " 'playing': 4.012969059033589,\n",
       " 'possibilities': 7.23307489635699,\n",
       " 'quick': 4.427851450170062,\n",
       " 'row': 6.649570893246872,\n",
       " 'simple': 3.940948609749196,\n",
       " 'sizes': 6.238399635561852,\n",
       " 'slightly': 5.055704229683201,\n",
       " 'stuck': 4.815102798289787,\n",
       " 'thinking': 4.019598236166559,\n",
       " 'three': 3.5515299665340128,\n",
       " 'tictactoe': 25.587513054745035,\n",
       " 'trying': 3.541506752319125,\n",
       " 'twist': 5.514437691957897,\n",
       " 'will': 1.6148503100624352,\n",
       " 'win': 5.780740737732887,\n",
       " 'wins': 7.210260218590818,\n",
       " 'year': 3.033504442923142}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query = querybuilder(\"\") # You can build the query by passing a string OR\n",
    "query = querybuilder(test.take(1)[0])  # Build the query from the test RDD using any of the documents\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = tfidf_docs.map(lambda x: cosine_similarity(x, query)) # Calculate the cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 185.0 failed 1 times, most recent failure: Lost task 0.0 in stage 185.0 (TID 183, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 2423, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 2423, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 346, in func\n    return f(iterator)\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 1290, in <lambda>\n    return self.mapPartitions(lambda it: [heapq.nsmallest(num, it, key)]).reduce(merge)\n  File \"/opt/conda/lib/python3.6/heapq.py\", line 516, in nsmallest\n    k = key(elem)\n  File \"<ipython-input-182-476a741fe417>\", line 1, in <lambda>\nTypeError: 'NoneType' object is not subscriptable\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2022)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2043)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2062)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2087)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:935)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:458)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 2423, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 2423, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 346, in func\n    return f(iterator)\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 1290, in <lambda>\n    return self.mapPartitions(lambda it: [heapq.nsmallest(num, it, key)]).reduce(merge)\n  File \"/opt/conda/lib/python3.6/heapq.py\", line 516, in nsmallest\n    k = key(elem)\n  File \"<ipython-input-182-476a741fe417>\", line 1, in <lambda>\nTypeError: 'NoneType' object is not subscriptable\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-476a741fe417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtakeOrdered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mtakeOrdered\u001b[0;34m(self, num, key)\u001b[0m\n\u001b[1;32m   1288\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mheapq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnsmallest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1290\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mheapq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnsmallest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \"\"\"\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m             \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 185.0 failed 1 times, most recent failure: Lost task 0.0 in stage 185.0 (TID 183, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 2423, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 2423, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 346, in func\n    return f(iterator)\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 1290, in <lambda>\n    return self.mapPartitions(lambda it: [heapq.nsmallest(num, it, key)]).reduce(merge)\n  File \"/opt/conda/lib/python3.6/heapq.py\", line 516, in nsmallest\n    k = key(elem)\n  File \"<ipython-input-182-476a741fe417>\", line 1, in <lambda>\nTypeError: 'NoneType' object is not subscriptable\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2022)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2043)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2062)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2087)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:935)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:458)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 2423, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 2423, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 346, in func\n    return f(iterator)\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 1290, in <lambda>\n    return self.mapPartitions(lambda it: [heapq.nsmallest(num, it, key)]).reduce(merge)\n  File \"/opt/conda/lib/python3.6/heapq.py\", line 516, in nsmallest\n    k = key(elem)\n  File \"<ipython-input-182-476a741fe417>\", line 1, in <lambda>\nTypeError: 'NoneType' object is not subscriptable\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "r.takeOrdered(10, key=lambda s: -s[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The rest of the section is optional and could be used if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.filter(lambda x: x is None).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = r.filter(lambda x: x is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(([('game', 2.706406938523856),\n",
       "    ('sweet', 4.885737082740047),\n",
       "    ('want', 7.631857485077642),\n",
       "    ('codes', 14.038409963656218),\n",
       "    ('got', 2.4623902718913246),\n",
       "    ('one', 1.0030553967683506),\n",
       "    ('sweetyou', 12.793756527372517),\n",
       "    ('get', 1.6623843504641405),\n",
       "    ('rocket', 7.342718073806817),\n",
       "    ('launcher', 8.786423342140047),\n",
       "    ('typing', 7.210260218590818),\n",
       "    ('code', 10.489347633120463),\n",
       "    ('hunting', 6.700186757327382),\n",
       "    ('just', 1.3527353106939637),\n",
       "    ('kill', 5.376776905991363),\n",
       "    ('blow', 5.92059269316),\n",
       "    ('away', 3.2705781630634356),\n",
       "    ('bhbbq', 12.793756527372517)],\n",
       "   0.4934579857224185),\n",
       "  429),\n",
       " (([('game', 8.119220815571568),\n",
       "    ('aged', 7.038014313785605),\n",
       "    ('well', 5.863291650359596),\n",
       "    ('went', 3.649235496433628),\n",
       "    ('back', 2.42032784754386),\n",
       "    ('original', 3.3589135280444937),\n",
       "    ('360', 13.00808191292704),\n",
       "    ('games', 8.549929229185166),\n",
       "    ('see', 5.099182615465329),\n",
       "    ('ones', 3.908315615664932),\n",
       "    ('worth', 2.7958228045444438),\n",
       "    ('still', 2.4818748272223448),\n",
       "    ('playingthis', 11.184318614938418),\n",
       "    ('bad', 2.5244460020006683),\n",
       "    ('lacks', 5.440034196972886),\n",
       "    ('quite', 3.3951953666713903),\n",
       "    ('areas', 5.555978335449074),\n",
       "    ('story', 2.362674733495161),\n",
       "    ('tutorial', 7.351338816850724),\n",
       "    ('guide', 4.301470971662464),\n",
       "    ('moves', 5.170114580860946),\n",
       "    ('will', 3.2297006201248704),\n",
       "    ('facing', 6.896602659735777),\n",
       "    ('challenges', 6.613739873719944),\n",
       "    ('needed', 3.949708628430027),\n",
       "    ('level', 4.3134348107321845),\n",
       "    ('without', 3.077201144188027),\n",
       "    ('guidance', 7.038014313785605),\n",
       "    ('complete', 4.005010645434383),\n",
       "    ('characters', 2.9905313967747835),\n",
       "    ('hokey', 7.866502842215312),\n",
       "    ('dialogue', 5.11635609685771),\n",
       "    ('pretty', 3.190496074790465),\n",
       "    ('stiff', 6.306072508887906),\n",
       "    ('animations', 8.31641971289431),\n",
       "    ('worse', 4.388165512537582),\n",
       "    ('talk', 4.811340180544784),\n",
       "    ('clear', 4.126592809379985),\n",
       "    ('throatsif', 12.793756527372517),\n",
       "    ('love', 2.058164523388654),\n",
       "    ('tony', 6.4221446801406605),\n",
       "    ('hawk', 7.557314564542568),\n",
       "    ('one', 2.0061107935367013),\n",
       "    ('probably', 3.53901656809965),\n",
       "    ('suit', 6.4428708106577774),\n",
       "    ('hand', 4.187454160884504),\n",
       "    ('casual', 6.336986871800354),\n",
       "    ('gamer', 7.252492982214091),\n",
       "    ('specifically', 6.101672784865889),\n",
       "    ('fan', 3.1480686728063008),\n",
       "    ('genre', 5.178951162661443),\n",
       "    ('pick', 4.419510345276213),\n",
       "    ('try', 3.335540967862941),\n",
       "    ('others', 3.5946793476750454)],\n",
       "   0.4934579857224185),\n",
       "  1503),\n",
       " (([('game', 8.119220815571568),\n",
       "    ('rules', 5.739306869239576),\n",
       "    ('ok', 4.4280841435975224),\n",
       "    ('kicks', 6.709257114297346),\n",
       "    ('doubt', 4.959760185663057),\n",
       "    ('graphics', 14.46594121347567),\n",
       "    ('may', 3.2398264510062575),\n",
       "    ('little', 2.3431596389931517),\n",
       "    ('outdated', 5.913372445186512),\n",
       "    ('point', 3.6841208595179666),\n",
       "    ('playing', 4.012969059033589),\n",
       "    ('just', 2.7054706213879274),\n",
       "    ('everyone', 3.834830588677574),\n",
       "    ('needs', 3.9832968852105983),\n",
       "    ('stop', 4.2198050021376705),\n",
       "    ('comparing', 6.686733639630263),\n",
       "    ('ff8', 30.06350341539821),\n",
       "    ('great', 1.2283240049232733),\n",
       "    ('play', 3.2419563772640827),\n",
       "    ('ff7', 9.702714074014201),\n",
       "    ('day', 3.081611094851427),\n",
       "    ('lot', 2.9184112807826694),\n",
       "    ('fun', 3.102039939855632),\n",
       "    ('opinion', 4.322607274457686),\n",
       "    ('lots', 8.464327497319191),\n",
       "    ('secrets', 6.265798609749966),\n",
       "    ('find', 2.5932803430643085),\n",
       "    ('buy', 2.093798352044543),\n",
       "    ('now', 2.3981064279009123)],\n",
       "   0.4934579857224185),\n",
       "  3310),\n",
       " (([('game', 5.412813877047712),\n",
       "    ('stinks', 6.0014120999017075),\n",
       "    ('games', 4.274964614592583),\n",
       "    ('graphics', 4.82198040449189),\n",
       "    ('pretty', 3.190496074790465),\n",
       "    ('good', 1.2718713210308168),\n",
       "    ('gameplay', 6.164393273935069),\n",
       "    ('really', 1.837438878823407),\n",
       "    ('badthe', 8.682882663199205),\n",
       "    ('music', 2.472249668156873),\n",
       "    ('bad', 2.5244460020006683),\n",
       "    ('mean', 4.410323326135805),\n",
       "    ('heard', 3.5683305179782936),\n",
       "    ('sloppy', 6.579148428950326),\n",
       "    ('meat', 5.991361764048206),\n",
       "    ('eatersall', 12.793756527372517),\n",
       "    ('rate', 4.767913183221614),\n",
       "    ('10', 5.185878454094009)],\n",
       "   0.4934579857224185),\n",
       "  4787),\n",
       " (([('game', 8.119220815571568),\n",
       "    ('narrowing', 10.021167805132736),\n",
       "    ('choices', 11.973854333960682),\n",
       "    ('make', 4.9091960493423175),\n",
       "    ('educated', 14.038409963656218),\n",
       "    ('guess', 8.062533960001874),\n",
       "    ('enjoyable', 4.621309709029738),\n",
       "    ('young', 3.99651029066899),\n",
       "    ('old', 2.6210436857351747),\n",
       "    ('alike', 6.326057801268163),\n",
       "    ('mixing', 6.425569341022025),\n",
       "    ('matchingyou', 12.793756527372517),\n",
       "    ('try', 3.335540967862941),\n",
       "    ('figure', 4.634667872704607),\n",
       "    ('person', 7.852940006766204),\n",
       "    ('begin', 5.281685281537051),\n",
       "    ('asking', 5.86326176142089),\n",
       "    ('questions', 4.771187580384263),\n",
       "    ('blonde', 7.300695084031969),\n",
       "    ('hair', 4.178167014100087),\n",
       "    ('mustache', 9.032556411678955),\n",
       "    ('etc', 3.9714343499007785),\n",
       "    ('narrow', 6.354406156272419),\n",
       "    ('isits', 9.849317548206077),\n",
       "    ('lot', 2.9184112807826694),\n",
       "    ('fun', 3.102039939855632),\n",
       "    ('kids', 3.6310320093379977),\n",
       "    ('will', 1.6148503100624352),\n",
       "    ('enjoy', 3.470444676737173),\n",
       "    ('recommend', 2.608516950415409),\n",
       "    ('anyone', 3.0521410547629344)],\n",
       "   0.4934579857224185),\n",
       "  5364)]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attach the document id and then sort\n",
    "r.zipWithIndex().takeOrdered(5, key=lambda s: -s[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_original_record_ids(result_rdd, number):\n",
    "    ids = []\n",
    "    r_rdd = result_rdd.zipWithIndex()\n",
    "    r_rdd_sorted = r_rdd.takeOrdered(number, key=lambda s: -s[0][1])\n",
    "    i = 0\n",
    "    for rec in r_rdd_sorted:\n",
    "        ids.append((rec[1], i))\n",
    "        i = i+1\n",
    "    return ids\n",
    "\n",
    "def filter_records_on_ids(training_record, oids):\n",
    "    position = training_record[1]\n",
    "    for oid in oids:\n",
    "        if position == oid[0]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def map_final_records(training_record, oids):\n",
    "    position = training_record[1]\n",
    "    for oid in oids:\n",
    "        if position == oid[0]:\n",
    "            return (training_record, oid[1])\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(429, 0),\n",
       " (1503, 1),\n",
       " (3310, 2),\n",
       " (4787, 3),\n",
       " (5364, 4),\n",
       " (5396, 5),\n",
       " (5423, 6),\n",
       " (7429, 7),\n",
       " (10421, 8),\n",
       " (10662, 9)]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oids = get_original_record_ids(r, 10)\n",
    "oids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((\"__label__2 This game is Sweet.: If you want codes I got codes only one but its Sweet.You can get a rocket launcher by typing in this code when your hunting and you don't just want to kill it you want to blow it away that code is BHB-BQ\",\n",
       "   429),\n",
       "  0),\n",
       " ((\"__label__1 This Game Hasn't Aged Well: I went back through the original 360 games to see which ones were worth still playing.This game isn't all that bad but lacks in quite a few areas. The story tutorial doesn't guide you through the moves very well. You will be facing challenges needed to level up without any guidance on how to complete them. The characters are very hokey and the dialogue is pretty stiff. The animations are worse as when they talk you can see clear down their throats.If you love Tony Hawk games then this one will probably suit you well. If on the other hand you are a casual gamer and not specifically fan of the genre then dont pick up this game and try one of the 6 others for the 360.\",\n",
       "   1503),\n",
       "  1),\n",
       " ((\"__label__2 This game rules.: Ok. This game kicks. There's no doubt about it. The graphics may be a little outdated. But what's the point of playing a game just for it's graphics? And everyone needs to stop comparing it to FF8. So what if FF8 has great graphics? I would play FF7 over FF8 any day. It's a lot more fun in my opinion, and there's lots and lots of secrets to find. Just buy it. NOW!\",\n",
       "   3310),\n",
       "  2),\n",
       " (('__label__1 This game STINKS!: The games graphics are pretty good, but the gameplay is REALLY bad!The music is bad too, I mean, who\\'s heard of \"the sloppy meat eaters?\"All in all I rate this game a 2 out of 10.',\n",
       "   4787),\n",
       "  3),\n",
       " (('__label__2 The game of narrowing your choices to make an educated guess: This is a very enjoyable game for the young and old alike. It\\'s a game of mixing and matching.You try to figure out who the other person has. You begin by asking questions such as: \"Does this person have blonde hair? Do they have a mustache?\", etc. You narrow your choices down until you can make an educated guess on who it is!It\\'s a lot of fun and kids will enjoy it! I would recommend it to anyone.',\n",
       "   5364),\n",
       "  4),\n",
       " (('__label__1 This Game is Anti-Republican: The game has decent graphics. Destroying building with your flying saucer is fun at first but gets tedious. The \"stealth\" based missions are frustrating. With no mission save points if you make a mistake, then you may find yourself forced to start the mission over.The hardest flaw in the game for me to get over is the blatant pushing of liberal politics. It takes cheap shots at President George W. Bush with sayings like \"I should have joined the Texas Air National Guard. Now that would be some easy duty.\" Both Nixon and Sen. Joe McCarthy are mocked. Communism is treated like an imaginary threat or a conspiracy theory. When you scan the brains of many pedistrian NPCs, they have homosexual thoughts. Who thinks that is fun? Who is the target audience here?The developer is located in Australia. I think they have a flawed image of the United States of America. They certainly have little idea what is fun.',\n",
       "   5396),\n",
       "  5),\n",
       " (('__label__2 Same game but no plastic guide: My kids love Jenga but I was disappointed that this did not come with a plastic guide to help them stack the blocks. It did have a very thin, cardboard one that is completely useless.',\n",
       "   5423),\n",
       "  6),\n",
       " ((\"__label__1 This game is only a Contender for the worst game of the year: I'll cut to the chase here, and this game is awful. You name it, gameplay, graphics, audio....they're all awful. Stay away from this poor excuse for a game\",\n",
       "   7429),\n",
       "  7),\n",
       " ((\"__label__1 CHESS MASTER: I WAS NOT ABLE TO USE IT WITH MY COMPUTER BECAUSE IT REQUIRES TOO MUCH MEMORY USE. YOU HAVE TO INSTALL 3 OR 4 C/D'S INTO YOUR COMPUTER. I HAVE A 2 G/B COMPUTER THAT I JUST GOT AND MORE THAN HALF OF MY MEMORY WAS USED BECAUSE OF THIS GAME. IT GAVE ME WARNING ABOUT THE MEMORY SO I UNINSTALLED. I AM GOING TO HAVE TO BUY EXTERNAL MEMORY FOR THIS ONE.\",\n",
       "   10421),\n",
       "  8),\n",
       " (('__label__1 old time language, convoluted writing style: I bought \"The Three Magic Words\" by US Anderson because it was chosen by the book club to which I belong. I wish I had not bought it. The author\\'s writing style is convoluted, patriarchal and exclusive. It is all about men. I haven\\'t read a book like that in over a decade and had forgotten what it was like to read a so-called metaphysical book that excludes half of the human race. Also, since his book was written so long ago, he has nothing new to say. I consider reading this book a waste of time. Other authors, like Wayne Dyer, Caroline Myss, Bruce Lipton, Dawson Church, David Feinstein and Donna Eden and Robert Schwartz just to name a few, are far more informative and their writing style is easier to digest. Anyway, that\\'s my opinion.',\n",
       "   10662),\n",
       "  9)]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the full content of the matched documents\n",
    "train.zipWithIndex().filter(lambda x: filter_records_on_ids(x, oids)).map(lambda x: map_final_records(x, oids)).takeOrdered(10, lambda s: s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
